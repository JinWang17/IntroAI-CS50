{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "saving-stand",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %load nim.py\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "thermal-unemployment",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(n):\n",
    "    \"\"\"\n",
    "    Train an AI by playing `n` games against itself.\n",
    "    \"\"\"\n",
    "\n",
    "    player = NimAI()\n",
    "\n",
    "    # Play n games\n",
    "    for i in range(n):\n",
    "        if i % 1000 == 0:\n",
    "            print(f\"Playing training game {i + 1}\")\n",
    "        game = Nim()\n",
    "\n",
    "        # Keep track of last move made by either player\n",
    "        last = {\n",
    "            0: {\"state\": None, \"action\": None},\n",
    "            1: {\"state\": None, \"action\": None}\n",
    "        }\n",
    "\n",
    "        # Game loop\n",
    "        while True:\n",
    "\n",
    "            # Keep track of current state and action\n",
    "            state = game.piles.copy()\n",
    "            action = player.choose_action(game.piles)\n",
    "\n",
    "            # Keep track of last state and action\n",
    "            last[game.player][\"state\"] = state\n",
    "            last[game.player][\"action\"] = action\n",
    "\n",
    "            # Make move\n",
    "            game.move(action)\n",
    "            new_state = game.piles.copy()\n",
    "\n",
    "            # When game is over, update Q values with rewards\n",
    "            if game.winner is not None:\n",
    "                # update input: old_state, action, new_state, reward\n",
    "                # ??? What is the difference between these two lines???\n",
    "                # updated twice = not updated???\n",
    "                player.update(state, action, new_state, -1)\n",
    "                player.update(\n",
    "                    last[game.player][\"state\"],\n",
    "                    last[game.player][\"action\"],\n",
    "                    new_state,\n",
    "                    1\n",
    "                )\n",
    "                break\n",
    "\n",
    "            # If game is continuing, no rewards yet\n",
    "            elif last[game.player][\"state\"] is not None:\n",
    "                player.update(\n",
    "                    last[game.player][\"state\"],\n",
    "                    last[game.player][\"action\"],\n",
    "                    new_state,\n",
    "                    0\n",
    "                )\n",
    "\n",
    "    print(\"Done training\")\n",
    "\n",
    "    # Return the trained AI\n",
    "    return player\n",
    "\n",
    "\n",
    "def play(ai, human_player=None):\n",
    "    \"\"\"\n",
    "    Play human game against the AI.\n",
    "    `human_player` can be set to 0 or 1 to specify whether\n",
    "    human player moves first or second.\n",
    "    \"\"\"\n",
    "\n",
    "    # If no player order set, choose human's order randomly\n",
    "    if human_player is None:\n",
    "        human_player = random.randint(0, 1)\n",
    "\n",
    "    # Create new game\n",
    "    game = Nim()\n",
    "\n",
    "    # Game loop\n",
    "    while True:\n",
    "\n",
    "        # Print contents of piles\n",
    "        print()\n",
    "        print(\"Piles:\")\n",
    "        for i, pile in enumerate(game.piles):\n",
    "            print(f\"Pile {i}: {pile}\")\n",
    "        print()\n",
    "\n",
    "        # Compute available actions\n",
    "        available_actions = Nim.available_actions(game.piles)\n",
    "        time.sleep(1)\n",
    "\n",
    "        # Let human make a move\n",
    "        if game.player == human_player:\n",
    "            print(\"Your Turn\")\n",
    "            while True:\n",
    "                pile = int(input(\"Choose Pile: \"))\n",
    "                count = int(input(\"Choose Count: \"))\n",
    "                if (pile, count) in available_actions:\n",
    "                    break\n",
    "                print(\"Invalid move, try again.\")\n",
    "\n",
    "        # Have AI make a move\n",
    "        else:\n",
    "            print(\"AI's Turn\")\n",
    "            pile, count = ai.choose_action(game.piles, epsilon=False)\n",
    "            print(f\"AI chose to take {count} from pile {pile}.\")\n",
    "\n",
    "        # Make move\n",
    "        game.move((pile, count))\n",
    "\n",
    "        # Check for winner\n",
    "        if game.winner is not None:\n",
    "            print()\n",
    "            print(\"GAME OVER\")\n",
    "            winner = \"Human\" if game.winner == human_player else \"AI\"\n",
    "            print(f\"Winner is {winner}\")\n",
    "            return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bronze-olive",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Nim():\n",
    "\n",
    "    def __init__(self, initial=[1, 3, 5, 7]):\n",
    "        \"\"\"\n",
    "        Initialize game board.\n",
    "        Each game board has\n",
    "            - `piles`: a list of how many elements remain in each pile\n",
    "            - `player`: 0 or 1 to indicate which player's turn\n",
    "            - `winner`: None, 0, or 1 to indicate who the winner is\n",
    "        \"\"\"\n",
    "        self.piles = initial.copy()\n",
    "        self.player = 0\n",
    "        self.winner = None\n",
    "\n",
    "    @classmethod\n",
    "    def available_actions(cls, piles):\n",
    "        \"\"\"\n",
    "        Nim.available_actions(piles) takes a `piles` list as input\n",
    "        and returns all of the available actions `(i, j)` in that state.\n",
    "\n",
    "        Action `(i, j)` represents the action of removing `j` items\n",
    "        from pile `i` (where piles are 0-indexed).\n",
    "        \"\"\"\n",
    "        actions = set()\n",
    "        for i, pile in enumerate(piles):\n",
    "            for j in range(1, pile + 1):\n",
    "                actions.add((i, j))\n",
    "        return actions\n",
    "\n",
    "    @classmethod\n",
    "    def other_player(cls, player):\n",
    "        \"\"\"\n",
    "        Nim.other_player(player) returns the player that is not\n",
    "        `player`. Assumes `player` is either 0 or 1.\n",
    "        \"\"\"\n",
    "        return 0 if player == 1 else 1\n",
    "\n",
    "    def switch_player(self):\n",
    "        \"\"\"\n",
    "        Switch the current player to the other player.\n",
    "        \"\"\"\n",
    "        self.player = Nim.other_player(self.player)\n",
    "\n",
    "    def move(self, action):\n",
    "        \"\"\"\n",
    "        Make the move `action` for the current player.\n",
    "        `action` must be a tuple `(i, j)`.\n",
    "        \"\"\"\n",
    "        pile, count = action\n",
    "\n",
    "        # Check for errors\n",
    "        if self.winner is not None:\n",
    "            raise Exception(\"Game already won\")\n",
    "        elif pile < 0 or pile >= len(self.piles):\n",
    "            raise Exception(\"Invalid pile\")\n",
    "        elif count < 1 or count > self.piles[pile]:\n",
    "            raise Exception(\"Invalid number of objects\")\n",
    "\n",
    "        # Update pile\n",
    "        self.piles[pile] -= count\n",
    "        self.switch_player()\n",
    "\n",
    "        # Check for a winner\n",
    "        if all(pile == 0 for pile in self.piles):\n",
    "            self.winner = self.player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "earlier-impossible",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NimAI():\n",
    "\n",
    "    def __init__(self, alpha=0.5, epsilon=0.1):\n",
    "        \"\"\"\n",
    "        Initialize AI with an empty Q-learning dictionary,\n",
    "        an alpha (learning) rate, and an epsilon rate.\n",
    "\n",
    "        The Q-learning dictionary maps `(state, action)`\n",
    "        pairs to a Q-value (a number).\n",
    "         - `state` is a tuple of remaining piles, e.g. (1, 1, 4, 4)\n",
    "         - `action` is a tuple `(i, j)` for an action\n",
    "        \"\"\"\n",
    "        self.q = dict()\n",
    "        self.alpha = alpha\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def update(self, old_state, action, new_state, reward):\n",
    "        \"\"\"\n",
    "        Update Q-learning model, given an old state, an action taken\n",
    "        in that state, a new resulting state, and the reward received\n",
    "        from taking that action.\n",
    "        \"\"\"\n",
    "        old = self.get_q_value(old_state, action)\n",
    "        best_future = self.best_future_reward(new_state)\n",
    "        self.update_q_value(old_state, action, old, reward, best_future)\n",
    "\n",
    "    def get_q_value(self, state, action):\n",
    "        \"\"\"\n",
    "        Return the Q-value for the state `state` and the action `action`.\n",
    "        If no Q-value exists yet in `self.q`, return 0.\n",
    "        \"\"\"\n",
    "        state = tuple(state)\n",
    "        if (state, action) in self.q.keys():\n",
    "            return self.q[(state, action)]\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def update_q_value(self, state, action, old_q, reward, future_rewards):\n",
    "        \"\"\"\n",
    "        Update the Q-value for the state `state` and the action `action`\n",
    "        given the previous Q-value `old_q`, a current reward `reward`,\n",
    "        and an estiamte of future rewards `future_rewards`.\n",
    "\n",
    "        Use the formula:\n",
    "\n",
    "        Q(s, a) <- old value estimate\n",
    "                   + alpha * (new value estimate - old value estimate)\n",
    "\n",
    "        where `old value estimate` is the previous Q-value,\n",
    "        `alpha` is the learning rate, and `new value estimate`\n",
    "        is the sum of the current reward and estimated future rewards.\n",
    "        \"\"\"\n",
    "        state = tuple(state)\n",
    "        self.q[(state, action)] = old_q + self.alpha * (reward + future_rewards - old_q)\n",
    "\n",
    "        \n",
    "    def best_future_reward(self, state):\n",
    "        \"\"\"\n",
    "        Given a state `state`, consider all possible `(state, action)`\n",
    "        pairs available in that state and return the maximum of all\n",
    "        of their Q-values.\n",
    "\n",
    "        Use 0 as the Q-value if a `(state, action)` pair has no\n",
    "        Q-value in `self.q`. If there are no available actions in\n",
    "        `state`, return 0.\n",
    "        \"\"\"\n",
    "        actions = Nim.available_actions(state)\n",
    "        state = tuple(state)\n",
    "        if actions:\n",
    "            best = 0\n",
    "            for action in actions:\n",
    "                if (state, action) in self.q.keys() and self.q[(state, action)] > best:\n",
    "                    best = self.q[(state, action)]\n",
    "            return best\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def choose_action(self, state, epsilon=True):\n",
    "        \"\"\"\n",
    "        Given a state `state`, return an action `(i, j)` to take.\n",
    "\n",
    "        If `epsilon` is `False`, then return the best action\n",
    "        available in the state (the one with the highest Q-value,\n",
    "        using 0 for pairs that have no Q-values).\n",
    "\n",
    "        If `epsilon` is `True`, then with probability\n",
    "        `self.epsilon` choose a random available action,\n",
    "        otherwise choose the best action available.\n",
    "\n",
    "        If multiple actions have the same Q-value, any of those\n",
    "        options is an acceptable return value.\n",
    "        \"\"\"\n",
    "        actions = Nim.available_actions(state)\n",
    "        if epsilon and random.random() < self.epsilon:\n",
    "            return random.choice(list(actions)) # if error, change actions to list(actions)\n",
    "        best = float(\"-inf\")\n",
    "        best_action = None\n",
    "        unevaluated_action = None \n",
    "        state = tuple(state)\n",
    "        \n",
    "        for action in actions:\n",
    "            if (state, action) in self.q.keys() and self.q[(state, action)] > best:\n",
    "                best = self.q[(state, action)]\n",
    "                best_action = action\n",
    "            elif (state, action) not in self.q.keys():\n",
    "                unevaluated_action = action\n",
    "        \n",
    "        if best_action is None:\n",
    "            best_action = unevaluated_action\n",
    "        if not best_action:\n",
    "            print(best_action)\n",
    "            print(unevaluated_action)\n",
    "            print(state)\n",
    "            print(actions)\n",
    "            print(self.q)\n",
    "        return best_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "better-strip",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Playing training game 1\n",
      "Playing training game 101\n",
      "Playing training game 201\n",
      "Playing training game 301\n",
      "Playing training game 401\n",
      "Playing training game 501\n",
      "Playing training game 601\n",
      "Playing training game 701\n",
      "Playing training game 801\n",
      "Playing training game 901\n",
      "Playing training game 1001\n",
      "Playing training game 1101\n",
      "Playing training game 1201\n",
      "Playing training game 1301\n",
      "Playing training game 1401\n",
      "Playing training game 1501\n",
      "Playing training game 1601\n",
      "Playing training game 1701\n",
      "Playing training game 1801\n",
      "Playing training game 1901\n",
      "Playing training game 2001\n",
      "Playing training game 2101\n",
      "Playing training game 2201\n",
      "Playing training game 2301\n",
      "Playing training game 2401\n",
      "Playing training game 2501\n",
      "Playing training game 2601\n",
      "Playing training game 2701\n",
      "Playing training game 2801\n",
      "Playing training game 2901\n",
      "Playing training game 3001\n",
      "Playing training game 3101\n",
      "Playing training game 3201\n",
      "Playing training game 3301\n",
      "Playing training game 3401\n",
      "Playing training game 3501\n",
      "Playing training game 3601\n",
      "Playing training game 3701\n",
      "Playing training game 3801\n",
      "Playing training game 3901\n",
      "Playing training game 4001\n",
      "Playing training game 4101\n",
      "Playing training game 4201\n",
      "Playing training game 4301\n",
      "Playing training game 4401\n",
      "Playing training game 4501\n",
      "Playing training game 4601\n",
      "Playing training game 4701\n",
      "Playing training game 4801\n",
      "Playing training game 4901\n",
      "Playing training game 5001\n",
      "Playing training game 5101\n",
      "Playing training game 5201\n",
      "Playing training game 5301\n",
      "Playing training game 5401\n",
      "Playing training game 5501\n",
      "Playing training game 5601\n",
      "Playing training game 5701\n",
      "Playing training game 5801\n",
      "Playing training game 5901\n",
      "Playing training game 6001\n",
      "Playing training game 6101\n",
      "Playing training game 6201\n",
      "Playing training game 6301\n",
      "Playing training game 6401\n",
      "Playing training game 6501\n",
      "Playing training game 6601\n",
      "Playing training game 6701\n",
      "Playing training game 6801\n",
      "Playing training game 6901\n",
      "Playing training game 7001\n",
      "Playing training game 7101\n",
      "Playing training game 7201\n",
      "Playing training game 7301\n",
      "Playing training game 7401\n",
      "Playing training game 7501\n",
      "Playing training game 7601\n",
      "Playing training game 7701\n",
      "Playing training game 7801\n",
      "Playing training game 7901\n",
      "Playing training game 8001\n",
      "Playing training game 8101\n",
      "Playing training game 8201\n",
      "Playing training game 8301\n",
      "Playing training game 8401\n",
      "Playing training game 8501\n",
      "Playing training game 8601\n",
      "Playing training game 8701\n",
      "Playing training game 8801\n",
      "Playing training game 8901\n",
      "Playing training game 9001\n",
      "Playing training game 9101\n",
      "Playing training game 9201\n",
      "Playing training game 9301\n",
      "Playing training game 9401\n",
      "Playing training game 9501\n",
      "Playing training game 9601\n",
      "Playing training game 9701\n",
      "Playing training game 9801\n",
      "Playing training game 9901\n",
      "Done training\n",
      "\n",
      "Piles:\n",
      "Pile 0: 1\n",
      "Pile 1: 3\n",
      "Pile 2: 5\n",
      "Pile 3: 7\n",
      "\n",
      "AI's Turn\n",
      "AI chose to take 3 from pile 3.\n",
      "\n",
      "Piles:\n",
      "Pile 0: 1\n",
      "Pile 1: 3\n",
      "Pile 2: 5\n",
      "Pile 3: 4\n",
      "\n",
      "Your Turn\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Choose Pile:  2\n",
      "Choose Count:  2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Piles:\n",
      "Pile 0: 1\n",
      "Pile 1: 3\n",
      "Pile 2: 3\n",
      "Pile 3: 4\n",
      "\n",
      "AI's Turn\n",
      "AI chose to take 3 from pile 3.\n",
      "\n",
      "Piles:\n",
      "Pile 0: 1\n",
      "Pile 1: 3\n",
      "Pile 2: 3\n",
      "Pile 3: 1\n",
      "\n",
      "Your Turn\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Choose Pile:  1\n",
      "Choose Count:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Piles:\n",
      "Pile 0: 1\n",
      "Pile 1: 2\n",
      "Pile 2: 3\n",
      "Pile 3: 1\n",
      "\n",
      "AI's Turn\n",
      "AI chose to take 1 from pile 0.\n",
      "\n",
      "Piles:\n",
      "Pile 0: 0\n",
      "Pile 1: 2\n",
      "Pile 2: 3\n",
      "Pile 3: 1\n",
      "\n",
      "Your Turn\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Choose Pile:  2\n",
      "Choose Count:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Piles:\n",
      "Pile 0: 0\n",
      "Pile 1: 2\n",
      "Pile 2: 2\n",
      "Pile 3: 1\n",
      "\n",
      "AI's Turn\n",
      "AI chose to take 1 from pile 3.\n",
      "\n",
      "Piles:\n",
      "Pile 0: 0\n",
      "Pile 1: 2\n",
      "Pile 2: 2\n",
      "Pile 3: 0\n",
      "\n",
      "Your Turn\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Choose Pile:  1\n",
      "Choose Count:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Piles:\n",
      "Pile 0: 0\n",
      "Pile 1: 1\n",
      "Pile 2: 2\n",
      "Pile 3: 0\n",
      "\n",
      "AI's Turn\n",
      "AI chose to take 2 from pile 2.\n",
      "\n",
      "Piles:\n",
      "Pile 0: 0\n",
      "Pile 1: 1\n",
      "Pile 2: 0\n",
      "Pile 3: 0\n",
      "\n",
      "Your Turn\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Choose Pile:  1\n",
      "Choose Count:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GAME OVER\n",
      "Winner is AI\n"
     ]
    }
   ],
   "source": [
    "# %load play.py\n",
    "#from nim import train, play\n",
    "\n",
    "ai = train(10000)\n",
    "play(ai)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "respected-minute",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Playing training game 1\n",
      "Playing training game 101\n",
      "Done training\n",
      "\n",
      "Piles:\n",
      "Pile 0: 1\n",
      "Pile 1: 3\n",
      "Pile 2: 5\n",
      "Pile 3: 7\n",
      "\n",
      "Your Turn\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Choose Pile:  3\n",
      "Choose Count:  3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Piles:\n",
      "Pile 0: 1\n",
      "Pile 1: 3\n",
      "Pile 2: 5\n",
      "Pile 3: 4\n",
      "\n",
      "AI's Turn\n",
      "AI chose to take 3 from pile 1.\n",
      "\n",
      "Piles:\n",
      "Pile 0: 1\n",
      "Pile 1: 0\n",
      "Pile 2: 5\n",
      "Pile 3: 4\n",
      "\n",
      "Your Turn\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Choose Pile:  3\n",
      "Choose Count:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Piles:\n",
      "Pile 0: 1\n",
      "Pile 1: 0\n",
      "Pile 2: 5\n",
      "Pile 3: 3\n",
      "\n",
      "AI's Turn\n",
      "AI chose to take 5 from pile 2.\n",
      "\n",
      "Piles:\n",
      "Pile 0: 1\n",
      "Pile 1: 0\n",
      "Pile 2: 0\n",
      "Pile 3: 3\n",
      "\n",
      "Your Turn\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Choose Pile:  3\n",
      "Choose Count:  3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Piles:\n",
      "Pile 0: 1\n",
      "Pile 1: 0\n",
      "Pile 2: 0\n",
      "Pile 3: 0\n",
      "\n",
      "AI's Turn\n",
      "AI chose to take 1 from pile 0.\n",
      "\n",
      "GAME OVER\n",
      "Winner is Human\n"
     ]
    }
   ],
   "source": [
    "ai_toy = train(200)\n",
    "play(ai_toy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "detailed-maximum",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Piles:\n",
      "Pile 0: 1\n",
      "Pile 1: 3\n",
      "Pile 2: 5\n",
      "Pile 3: 7\n",
      "\n",
      "Your Turn\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Choose Pile:  3\n",
      "Choose Count:  3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Piles:\n",
      "Pile 0: 1\n",
      "Pile 1: 3\n",
      "Pile 2: 5\n",
      "Pile 3: 4\n",
      "\n",
      "AI's Turn\n",
      "AI chose to take 1 from pile 2.\n",
      "\n",
      "Piles:\n",
      "Pile 0: 1\n",
      "Pile 1: 3\n",
      "Pile 2: 4\n",
      "Pile 3: 4\n",
      "\n",
      "Your Turn\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Choose Pile:  1\n",
      "Choose Count:  2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Piles:\n",
      "Pile 0: 1\n",
      "Pile 1: 1\n",
      "Pile 2: 4\n",
      "Pile 3: 4\n",
      "\n",
      "AI's Turn\n",
      "AI chose to take 1 from pile 2.\n",
      "\n",
      "Piles:\n",
      "Pile 0: 1\n",
      "Pile 1: 1\n",
      "Pile 2: 3\n",
      "Pile 3: 4\n",
      "\n",
      "Your Turn\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Choose Pile:  0\n",
      "Choose Count:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Piles:\n",
      "Pile 0: 0\n",
      "Pile 1: 1\n",
      "Pile 2: 3\n",
      "Pile 3: 4\n",
      "\n",
      "AI's Turn\n",
      "AI chose to take 2 from pile 3.\n",
      "\n",
      "Piles:\n",
      "Pile 0: 0\n",
      "Pile 1: 1\n",
      "Pile 2: 3\n",
      "Pile 3: 2\n",
      "\n",
      "Your Turn\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Choose Pile:  3\n",
      "Choose Count:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Piles:\n",
      "Pile 0: 0\n",
      "Pile 1: 1\n",
      "Pile 2: 3\n",
      "Pile 3: 1\n",
      "\n",
      "AI's Turn\n",
      "AI chose to take 2 from pile 2.\n",
      "\n",
      "Piles:\n",
      "Pile 0: 0\n",
      "Pile 1: 1\n",
      "Pile 2: 1\n",
      "Pile 3: 1\n",
      "\n",
      "Your Turn\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Choose Pile:  2\n",
      "Choose Count:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Piles:\n",
      "Pile 0: 0\n",
      "Pile 1: 1\n",
      "Pile 2: 0\n",
      "Pile 3: 1\n",
      "\n",
      "AI's Turn\n",
      "AI chose to take 1 from pile 1.\n",
      "\n",
      "Piles:\n",
      "Pile 0: 0\n",
      "Pile 1: 0\n",
      "Pile 2: 0\n",
      "Pile 3: 1\n",
      "\n",
      "Your Turn\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Choose Pile:  3\n",
      "Choose Count:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GAME OVER\n",
      "Winner is AI\n"
     ]
    }
   ],
   "source": [
    "play(ai, human_player=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spanish-cause",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
